{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c37b237-8565-4c62-8975-44de9082093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹ X shape: (144, 100, 32, 3) y shape: (144,)\n",
      "åŸå§‹ç±»åˆ«åˆ†å¸ƒ: Counter({np.str_('p_stand'): 45, np.str_('a_walk'): 28, np.str_('p_sit'): 27, np.str_('Unknown'): 17, np.str_('t_bend'): 7, np.str_('p_lie'): 6, np.str_('p_bent'): 6, np.str_('t_straighten'): 4, np.str_('t_bed_turn'): 3, np.str_('t_stand_to_sit'): 1})\n",
      "æ£€æµ‹å¹¶ç§»é™¤ 0 ä¸ªåæ ·æœ¬ï¼ˆå‰©ä½™ 144 ä¸ªï¼‰ï¼Œæ—¥å¿—ä¿å­˜è‡³ data/bad_samples.txt\n",
      "è¿‡æ»¤å X shape: (113, 100, 32, 3) y shape: (113,)\n",
      "ç‰¹å¾å±•å¼€å: (113, 100, 96)\n",
      "ç±»åˆ«æ˜ å°„: {np.str_('a_walk'): 0, np.str_('p_lie'): 1, np.str_('p_sit'): 2, np.str_('p_stand'): 3, np.str_('t_bend'): 4}\n",
      "è¿‡é‡‡æ ·åç±»åˆ«åˆ†å¸ƒ: Counter({np.int64(0): 45, np.int64(1): 45, np.int64(2): 45, np.int64(3): 45, np.int64(4): 45})\n",
      "Train: (135, 100, 96) Val: (45, 100, 96) Test: (45, 100, 96)\n",
      "Epoch 01/40 | Train F1: 0.3577 | Val F1: 0.1926 | Test F1: 0.1608\n",
      "Epoch 02/40 | Train F1: 0.4798 | Val F1: 0.4547 | Test F1: 0.3952\n",
      "Epoch 03/40 | Train F1: 0.4853 | Val F1: 0.5695 | Test F1: 0.4403\n",
      "Epoch 04/40 | Train F1: 0.5429 | Val F1: 0.5293 | Test F1: 0.5665\n",
      "Epoch 05/40 | Train F1: 0.5509 | Val F1: 0.5895 | Test F1: 0.5960\n",
      "Epoch 06/40 | Train F1: 0.5680 | Val F1: 0.6462 | Test F1: 0.5640\n",
      "Epoch 07/40 | Train F1: 0.5881 | Val F1: 0.6462 | Test F1: 0.5922\n",
      "Epoch 08/40 | Train F1: 0.6148 | Val F1: 0.5848 | Test F1: 0.5851\n",
      "Epoch 09/40 | Train F1: 0.5782 | Val F1: 0.6690 | Test F1: 0.6114\n",
      "Epoch 10/40 | Train F1: 0.5962 | Val F1: 0.6957 | Test F1: 0.6051\n",
      "Epoch 11/40 | Train F1: 0.6353 | Val F1: 0.7322 | Test F1: 0.6429\n",
      "Epoch 12/40 | Train F1: 0.6469 | Val F1: 0.7122 | Test F1: 0.6114\n",
      "Epoch 13/40 | Train F1: 0.6258 | Val F1: 0.7122 | Test F1: 0.6145\n",
      "Epoch 14/40 | Train F1: 0.6127 | Val F1: 0.6690 | Test F1: 0.6114\n",
      "Epoch 15/40 | Train F1: 0.6268 | Val F1: 0.7354 | Test F1: 0.6114\n",
      "Epoch 16/40 | Train F1: 0.6421 | Val F1: 0.7534 | Test F1: 0.6374\n",
      "Epoch 17/40 | Train F1: 0.6500 | Val F1: 0.7339 | Test F1: 0.6590\n",
      "Epoch 18/40 | Train F1: 0.6726 | Val F1: 0.7143 | Test F1: 0.6354\n",
      "Epoch 19/40 | Train F1: 0.6174 | Val F1: 0.7354 | Test F1: 0.6114\n",
      "Epoch 20/40 | Train F1: 0.6115 | Val F1: 0.7339 | Test F1: 0.6374\n",
      "Epoch 21/40 | Train F1: 0.6144 | Val F1: 0.7354 | Test F1: 0.6374\n",
      "Epoch 22/40 | Train F1: 0.6556 | Val F1: 0.7552 | Test F1: 0.6114\n",
      "Epoch 23/40 | Train F1: 0.7037 | Val F1: 0.7354 | Test F1: 0.6354\n",
      "Epoch 24/40 | Train F1: 0.6950 | Val F1: 0.7339 | Test F1: 0.6354\n",
      "Epoch 25/40 | Train F1: 0.6160 | Val F1: 0.7339 | Test F1: 0.6590\n",
      "Epoch 26/40 | Train F1: 0.6781 | Val F1: 0.7339 | Test F1: 0.6590\n",
      "Epoch 27/40 | Train F1: 0.6333 | Val F1: 0.7339 | Test F1: 0.6374\n",
      "Epoch 28/40 | Train F1: 0.6625 | Val F1: 0.7339 | Test F1: 0.6374\n",
      "Epoch 29/40 | Train F1: 0.6478 | Val F1: 0.7339 | Test F1: 0.6590\n",
      "Epoch 30/40 | Train F1: 0.6782 | Val F1: 0.7339 | Test F1: 0.6590\n",
      "âš ï¸ æå‰åœæ­¢ï¼šéªŒè¯é›† F1 æœªæå‡ã€‚\n",
      "âœ… æœ€ä½³éªŒè¯ F1: 0.7552\n",
      "\n",
      "ğŸ¯ æœ€ç»ˆæµ‹è¯•é›†æ€§èƒ½:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      a_walk       1.00      0.56      0.71         9\n",
      "       p_lie       0.47      0.89      0.62         9\n",
      "       p_sit       0.60      0.33      0.43         9\n",
      "     p_stand       0.80      0.44      0.57         9\n",
      "      t_bend       0.62      0.89      0.73         9\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.70      0.62      0.61        45\n",
      "weighted avg       0.70      0.62      0.61        45\n",
      "\n",
      "æ··æ·†çŸ©é˜µ:\n",
      "[[5 2 0 1 1]\n",
      " [0 8 1 0 0]\n",
      " [0 5 3 0 1]\n",
      " [0 1 1 4 3]\n",
      " [0 1 0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "\n",
    "# ===========================================================\n",
    "# Step 1. æ•°æ®åŠ è½½\n",
    "# ===========================================================\n",
    "data_path = \"data\"\n",
    "X = np.load(os.path.join(data_path, \"X.npy\"))\n",
    "y = np.load(os.path.join(data_path, \"y.npy\"))\n",
    "print(f\"åŸå§‹ X shape: {X.shape} y shape: {y.shape}\")\n",
    "print(\"åŸå§‹ç±»åˆ«åˆ†å¸ƒ:\", Counter(y))\n",
    "\n",
    "# ===========================================================\n",
    "# Step 2. è¿‡æ»¤åæ ·æœ¬\n",
    "# ===========================================================\n",
    "def filter_invalid_samples(X, y, max_abs=10000.0, min_std=1e-6, log_path=\"data/bad_samples.txt\"):\n",
    "    valid_idx, bad_info = [], []\n",
    "    for i in range(len(X)):\n",
    "        xi = X[i]\n",
    "        reason = None\n",
    "        if np.isnan(xi).any() or np.isinf(xi).any():\n",
    "            reason = \"NaN/Inf\"\n",
    "        elif np.allclose(xi, 0):\n",
    "            reason = \"All zeros\"\n",
    "        elif np.std(xi) < min_std:\n",
    "            reason = f\"Low std ({np.std(xi):.2e})\"\n",
    "        elif np.any(np.abs(xi) > max_abs):\n",
    "            reason = f\"Out of range (max={np.max(np.abs(xi)):.1f})\"\n",
    "\n",
    "        if reason:\n",
    "            bad_info.append(f\"Sample {i}: {reason}\")\n",
    "        else:\n",
    "            valid_idx.append(i)\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        if bad_info:\n",
    "            f.write(\"\\n\".join(bad_info))\n",
    "        else:\n",
    "            f.write(\"âœ… æ— åæ ·æœ¬\\n\")\n",
    "    print(f\"æ£€æµ‹å¹¶ç§»é™¤ {len(bad_info)} ä¸ªåæ ·æœ¬ï¼ˆå‰©ä½™ {len(valid_idx)} ä¸ªï¼‰ï¼Œæ—¥å¿—ä¿å­˜è‡³ {log_path}\")\n",
    "    return X[valid_idx], y[valid_idx]\n",
    "\n",
    "X, y = filter_invalid_samples(X, y)\n",
    "\n",
    "# ===========================================================\n",
    "# Step 3. ç­›é€‰ç›®æ ‡æ ‡ç­¾\n",
    "# ===========================================================\n",
    "target_labels = [\"p_sit\", \"p_stand\", \"a_walk\", \"p_lie\", \"t_bend\"]\n",
    "mask = np.isin(y, target_labels)\n",
    "X, y = X[mask], y[mask]\n",
    "print(f\"è¿‡æ»¤å X shape: {X.shape} y shape: {y.shape}\")\n",
    "\n",
    "# ===========================================================\n",
    "# Step 4. ç‰¹å¾å±•å¼€\n",
    "# ===========================================================\n",
    "N, T, J, C = X.shape\n",
    "X = X.reshape(N, T, J * C)\n",
    "print(f\"ç‰¹å¾å±•å¼€å: {X.shape}\")\n",
    "\n",
    "# ===========================================================\n",
    "# Step 5. æ ‡ç­¾ç¼–ç  + è¿‡é‡‡æ ·\n",
    "# ===========================================================\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"ç±»åˆ«æ˜ å°„:\", dict(zip(le.classes_, range(len(le.classes_)))))\n",
    "\n",
    "X_bal, y_bal = [], []\n",
    "for cls in np.unique(y):\n",
    "    X_cls = X[y == cls]\n",
    "    y_cls = y[y == cls]\n",
    "    X_up, y_up = resample(X_cls, y_cls, replace=True, n_samples=max(Counter(y).values()), random_state=42)\n",
    "    X_bal.append(X_up)\n",
    "    y_bal.append(y_up)\n",
    "X_res = np.vstack(X_bal)\n",
    "y_res = np.hstack(y_bal)\n",
    "print(\"è¿‡é‡‡æ ·åç±»åˆ«åˆ†å¸ƒ:\", Counter(y_res))\n",
    "\n",
    "# ===========================================================\n",
    "# Step 6. Train / Val / Test åˆ’åˆ†\n",
    "# ===========================================================\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "print(f\"Train: {X_train.shape} Val: {X_val.shape} Test: {X_test.shape}\")\n",
    "\n",
    "X_train, X_val, X_test = map(lambda x: torch.tensor(x, dtype=torch.float32), [X_train, X_val, X_test])\n",
    "y_train, y_val, y_test = map(lambda y: torch.tensor(y, dtype=torch.long), [y_train, y_val, y_test])\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=16, shuffle=False)\n",
    "\n",
    "# ===========================================================\n",
    "# Step 7. ST-GCN æ¨¡å‹å®šä¹‰ï¼ˆä¿®å¤ç‰ˆï¼‰\n",
    "# ===========================================================\n",
    "class STGCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size_t=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.temporal_conv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size_t, 1), padding=(1,0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, C, T, V]\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.relu(self.bn(x))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=5, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gcn1 = STGCNBlock(in_channels, 64)\n",
    "        self.gcn2 = STGCNBlock(64, 128)\n",
    "        self.gcn3 = STGCNBlock(128, 256)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # è¾“å…¥ x: [N, T, (J*C)]\n",
    "        N, T, D = x.shape\n",
    "        J = D // 3\n",
    "        x = x.view(N, T, J, 3).permute(0, 3, 1, 2)  # -> [N, C, T, J]\n",
    "        x = self.gcn1(x)\n",
    "        x = self.gcn2(x)\n",
    "        x = self.gcn3(x)\n",
    "        x = x.mean(dim=[2, 3])  # å…¨å±€å¹³å‡æ± åŒ–\n",
    "        return self.fc(x)\n",
    "\n",
    "# ===========================================================\n",
    "# Step 8. è®­ç»ƒä¸éªŒè¯ (F1-based Early Stopping)\n",
    "# ===========================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = STGCN(in_channels=3, num_classes=len(le.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "best_f1, patience, wait = 0.0, 8, 0\n",
    "\n",
    "for epoch in range(1, 41):\n",
    "    # ---------- Train ----------\n",
    "    model.train()\n",
    "    y_true, y_pred, train_loss = [], [], 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "        y_true.extend(yb.cpu().numpy())\n",
    "        y_pred.extend(out.argmax(1).cpu().numpy())\n",
    "    train_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "    y_val_true, y_val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            y_val_true.extend(yb.cpu().numpy())\n",
    "            y_val_pred.extend(out.argmax(1).cpu().numpy())\n",
    "    val_f1 = f1_score(y_val_true, y_val_pred, average='macro')\n",
    "\n",
    "    # ---------- Test ----------\n",
    "    y_test_true, y_test_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            y_test_true.extend(yb.cpu().numpy())\n",
    "            y_test_pred.extend(out.argmax(1).cpu().numpy())\n",
    "    test_f1 = f1_score(y_test_true, y_test_pred, average='macro')\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/40 | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f} | Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1, wait = val_f1, 0\n",
    "        torch.save(model.state_dict(), \"data/stgcn_pose5_fixed.pth\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"âš ï¸ æå‰åœæ­¢ï¼šéªŒè¯é›† F1 æœªæå‡ã€‚\")\n",
    "            break\n",
    "\n",
    "print(f\"âœ… æœ€ä½³éªŒè¯ F1: {best_f1:.4f}\")\n",
    "\n",
    "# ===========================================================\n",
    "# Step 9. æµ‹è¯•æŠ¥å‘Šè¾“å‡º\n",
    "# ===========================================================\n",
    "model.load_state_dict(torch.load(\"data/stgcn_pose5_fixed.pth\", weights_only=True))\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        y_true.extend(yb.cpu().numpy())\n",
    "        y_pred.extend(out.argmax(1).cpu().numpy())\n",
    "\n",
    "print(\"\\nğŸ¯ æœ€ç»ˆæµ‹è¯•é›†æ€§èƒ½:\")\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_, zero_division=0))\n",
    "print(\"æ··æ·†çŸ©é˜µ:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98ee2e-5906-4956-b5ef-63ee78eac229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
