{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e764d36-5cf8-438e-bee8-3cac37b3169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import itertools\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "LABELS = [\"walk\", \"stand\", \"sit\", \"bend\"] \n",
    "\n",
    "\n",
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, X, Y, label_to_idx=None):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape (N, 32, 4)\n",
    "        Y: numpy array of strings (e.g., \"walk\", \"sit\", ...)\n",
    "        \"\"\"\n",
    "\n",
    "       \n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = X.astype(np.float32)\n",
    "        else:\n",
    "            raise ValueError(\"X must be a numpy array\")\n",
    "\n",
    "       \n",
    "        if label_to_idx is None:\n",
    "            # 自动生成标签映射\n",
    "            uniq = sorted(list(set(Y.tolist())))\n",
    "            label_to_idx = {lb: i for i, lb in enumerate(uniq)}\n",
    "\n",
    "        # 保存映射\n",
    "        self.label_to_idx = label_to_idx\n",
    "\n",
    "        # 将字符串标签转换为 int\n",
    "        Y_idx = np.array([label_to_idx[y] for y in Y], dtype=np.int64)\n",
    "\n",
    "        # 转成 tensor \n",
    "        self.X = torch.tensor(X, dtype=torch.float32)   # (N, 32, 4)\n",
    "        self.Y = torch.tensor(Y_idx, dtype=torch.long)  # (N,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, num_class=4):\n",
    "        super().__init__()\n",
    "        self.gcn = nn.Sequential(\n",
    "            nn.Conv2d(4, 64, kernel_size=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=(1,1)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(256*32, num_class)\n",
    "\n",
    "    def forward(self, x):  # x: (N,32,4)\n",
    "        x = x.permute(0, 2, 1)        # -> (N,4,32)\n",
    "        x = x.unsqueeze(-1)          # -> (N,4,32,1)\n",
    "        x = self.gcn(x)              # -> (N,256,32,1)\n",
    "        x = x.view(x.size(0), -1)    # -> (N,256*32)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "\n",
    "# 加载 stgcn_dataset\n",
    "\n",
    "data = np.load(\"data/stgcn_dataset.npz\", allow_pickle=True)\n",
    "trainX, trainY = data[\"trainX\"], data[\"trainY\"]\n",
    "valX, valY     = data[\"valX\"],   data[\"valY\"]\n",
    "testX, testY   = data[\"testX\"],  data[\"testY\"]\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"Train:\", trainX.shape, trainY.shape)\n",
    "print(\"Val:  \", valX.shape, valY.shape)\n",
    "print(\"Test: \", testX.shape, testY.shape)\n",
    "\n",
    "train_loader = DataLoader(PoseDataset(trainX, trainY), batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(PoseDataset(valX,   valY),   batch_size=64)\n",
    "test_loader  = DataLoader(PoseDataset(testX,  testY),  batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "# Training Utils\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            out = model(X)\n",
    "            loss_sum += criterion(out, Y).item()\n",
    "            pred = out.argmax(1)\n",
    "            correct += (pred == Y).sum().item()\n",
    "            total += len(Y)\n",
    "    return loss_sum/len(loader), correct/total\n",
    "\n",
    "\n",
    "\n",
    "#  Train\n",
    "\n",
    "model = STGCN(num_class=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss_list, val_loss_list = [], []\n",
    "train_acc_list,  val_acc_list  = [], []\n",
    "\n",
    "EPOCH = 20\n",
    "\n",
    "print(\"\\n===== Training =====\")\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(1)\n",
    "        correct += (pred == Y).sum().item()\n",
    "        total += len(Y)\n",
    "\n",
    "    # validation\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    train_loss_list.append(total_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss)\n",
    "    train_acc_list.append(correct/total)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch} | Train Loss {train_loss_list[-1]:.4f} Acc {train_acc_list[-1]:.4f} \"\n",
    "          f\"| Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#  Test Evaluation\n",
    "\n",
    "model.eval()\n",
    "all_pred, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X).argmax(1).cpu().numpy()\n",
    "        all_pred.extend(pred)\n",
    "        all_true.extend(Y.numpy())\n",
    "\n",
    "print(\"\\n===== TEST RESULTS =====\")\n",
    "print(classification_report(all_true, all_pred, target_names=LABELS))\n",
    "print(\"Test Macro F1:\", f1_score(all_true, all_pred, average=\"macro\"))\n",
    "\n",
    "\n",
    "\n",
    "#  Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(all_true, all_pred)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(4), LABELS)\n",
    "plt.yticks(range(4), LABELS)\n",
    "\n",
    "for i, j in itertools.product(range(4), range(4)):\n",
    "    plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#  Loss & Accuracy Curves\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "plt.plot(val_loss_list, label=\"Val Loss\")\n",
    "plt.legend(); plt.title(\"Loss Curve\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_acc_list, label=\"Train Acc\")\n",
    "plt.plot(val_acc_list, label=\"Val Acc\")\n",
    "plt.legend(); plt.title(\"Accuracy Curve\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
