{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e75657d-5baa-4c2d-a6bf-2cd9883ddfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/40 | Train F1: 0.2638 | Val F1: 0.1250 | Test F1: 0.1708 | L: 1.0165\n",
      "Epoch 02/40 | Train F1: 0.2826 | Val F1: 0.1398 | Test F1: 0.1874 | L: 0.8945\n",
      "Epoch 03/40 | Train F1: 0.2996 | Val F1: 0.1506 | Test F1: 0.1890 | L: 0.8497\n",
      "Epoch 04/40 | Train F1: 0.3378 | Val F1: 0.1121 | Test F1: 0.1447 | L: 0.8171\n",
      "Epoch 05/40 | Train F1: 0.3930 | Val F1: 0.1820 | Test F1: 0.2463 | L: 0.7772\n",
      "Epoch 06/40 | Train F1: 0.4129 | Val F1: 0.1939 | Test F1: 0.2100 | L: 0.7600\n",
      "Epoch 07/40 | Train F1: 0.4526 | Val F1: 0.1308 | Test F1: 0.2385 | L: 0.7405\n",
      "Epoch 08/40 | Train F1: 0.4653 | Val F1: 0.1329 | Test F1: 0.2122 | L: 0.7298\n",
      "Epoch 09/40 | Train F1: 0.5187 | Val F1: 0.1437 | Test F1: 0.2644 | L: 0.6892\n",
      "Epoch 10/40 | Train F1: 0.5362 | Val F1: 0.1739 | Test F1: 0.2474 | L: 0.6798\n",
      "Epoch 11/40 | Train F1: 0.5188 | Val F1: 0.1496 | Test F1: 0.2043 | L: 0.6798\n",
      "âš ï¸ Early stop\n",
      "\n",
      "ğŸ¯ æœ€ç»ˆæµ‹è¯•é›†æ€§èƒ½ (Test Set):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      a_walk       0.48      0.07      0.13       530\n",
      "       a_lie       0.33      0.01      0.01       153\n",
      "     a_stand       0.45      0.68      0.54      1037\n",
      "       a_sit       0.29      0.42      0.34       540\n",
      "      a_bend       0.00      0.00      0.00       188\n",
      "\n",
      "    accuracy                           0.40      2448\n",
      "   macro avg       0.31      0.24      0.20      2448\n",
      "weighted avg       0.38      0.40      0.33      2448\n",
      "\n",
      "æ··æ·†çŸ©é˜µ:\n",
      "[[ 39   2 381 108   0]\n",
      " [  1   1  46 105   0]\n",
      " [ 19   0 701 317   0]\n",
      " [  9   0 300 229   2]\n",
      " [ 13   0 133  42   0]]\n"
     ]
    }
   ],
   "source": [
    "# === ä¸€é”®è·‘ï¼šä¿®å¤æ¨¡å‹ â†’ æ‰“åŒ…æ•°æ®(è‹¥ç¼º) â†’ è®­ç»ƒ(æ—©åœ) â†’ æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š & æ··æ·†çŸ©é˜µ ===\n",
    "import os, numpy as np, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# ä»ä½ çš„ pipeline å¯¼å…¥è¿™äº›å·²æœ‰å·¥å…·ï¼ˆå®ƒä»¬åœ¨ä½ çš„ stgcn_fiveclass_pipeline.py é‡Œï¼‰\n",
    "from stgcn_fiveclass_pipeline import (\n",
    "    Graph, STGCNWindowDataset, DefaultPaths, pack_train_val_test, FIVE_LABELS\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------\n",
    "# 1) ä¿®å¤ç‰ˆ GCN / STGCNï¼ˆé€šé“æ•°å¯¹é½ï¼š3â†’64â†’...ï¼‰\n",
    "# ----------------------------\n",
    "class GCN_Fix(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, A: np.ndarray, num_subset: int = 3):\n",
    "        super().__init__()\n",
    "        self.register_buffer('A', torch.tensor(A, dtype=torch.float32))  # (3,V,V)\n",
    "        self.num_subset = num_subset\n",
    "        # ç”¨ 1x1 å·ç§¯ç›´æ¥æŠŠ in_channels â†’ out_channelsï¼Œé¿å…é€šé“ä¸åŒ¹é…\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels, out_channels, 1) for _ in range(num_subset)])\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.down = nn.Identity() if (in_channels == out_channels) else nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):  # x: (N,C,T,V)\n",
    "        y = None\n",
    "        A = self.A\n",
    "        for i in range(self.num_subset):\n",
    "            z = torch.einsum('nctv,vw->nctw', x, A[i])  # å›¾èšåˆï¼Œä¸æ”¹å˜é€šé“æ•°\n",
    "            z = self.convs[i](z)                       # é€šé“å¯¹é½åˆ° out_channels\n",
    "            y = z if y is None else y + z\n",
    "        y = self.bn(y)\n",
    "        y = y + self.down(x)\n",
    "        return self.relu(y)\n",
    "\n",
    "class STGCN_Compat(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_class: int, A: np.ndarray):\n",
    "        super().__init__()\n",
    "        V = A.shape[-1]\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * V)\n",
    "        # GCN + TCN\n",
    "        self.g1 = GCN_Fix(in_channels, 64, A);  self.t1 = nn.Sequential(nn.Conv2d(64,64,(9,1),padding=(4,0)), nn.BatchNorm2d(64), nn.ReLU(True))\n",
    "        self.g2 = GCN_Fix(64, 64, A);           self.t2 = nn.Sequential(nn.Conv2d(64,64,(9,1),padding=(4,0)), nn.BatchNorm2d(64), nn.ReLU(True))\n",
    "        self.g3 = GCN_Fix(64,128, A);           self.t3 = nn.Sequential(nn.Conv2d(128,128,(9,1),padding=(4,0)), nn.BatchNorm2d(128), nn.ReLU(True))\n",
    "        self.g4 = GCN_Fix(128,256, A);          self.t4 = nn.Sequential(nn.Conv2d(256,256,(9,1),padding=(4,0)), nn.BatchNorm2d(256), nn.ReLU(True))\n",
    "        self.head = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Dropout(0.5), nn.Linear(256, num_class))\n",
    "\n",
    "    def forward(self, x):  # x: (N,3,T,32)\n",
    "        N, C, T, V = x.shape\n",
    "        x = x.permute(0,2,1,3).contiguous().view(N, T, C*V)\n",
    "        x = self.data_bn(x.transpose(1,2)).transpose(1,2)\n",
    "        x = x.view(N, T, C, V).permute(0,2,1,3).contiguous()\n",
    "        x = self.t1(self.g1(x))\n",
    "        x = self.t2(self.g2(x))\n",
    "        x = self.t3(self.g3(x))\n",
    "        x = self.t4(self.g4(x))\n",
    "        return self.head(x)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) è‹¥æ‰“åŒ…æ•°æ®ä¸å­˜åœ¨ï¼Œåˆ™è‡ªåŠ¨æ‰“åŒ…ï¼ˆç”¨ä½ åˆšå¯¼å‡ºçš„ä¸‰ä»½æ ‡ç­¾ï¼‰\n",
    "# ----------------------------\n",
    "paths = DefaultPaths(\n",
    "    lab_16gz=\"data/labels_16GZ.npy\",\n",
    "    lab_17jp=\"data/labels_17JP.npy\",\n",
    "    lab_19mm=\"data/labels_19MM.npy\",\n",
    ")\n",
    "need_pack = any(not os.path.isfile(p) for p in [paths.out_train, paths.out_val, paths.out_test])\n",
    "if need_pack:\n",
    "    print(\"âš™ï¸ æœªæ‰¾åˆ°æ‰“åŒ…æ–‡ä»¶ï¼Œæ­£åœ¨æ‰“åŒ… train/val/test ...\")\n",
    "    pack_train_val_test(win=120, stride=30, strict=True, mode=\"center\", paths=paths)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) DataLoader\n",
    "# ----------------------------\n",
    "train_ds = STGCNWindowDataset(paths.out_train)\n",
    "val_ds   = STGCNWindowDataset(paths.out_val)\n",
    "test_ds  = STGCNWindowDataset(paths.out_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) è®­ç»ƒï¼ˆæ—©åœæŒ‡æ ‡ï¼šVal macro-F1ï¼‰\n",
    "# ----------------------------\n",
    "A = Graph().A\n",
    "model = STGCN_Compat(in_channels=3, num_class=len(FIVE_LABELS), A=A).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "patience = 5\n",
    "best_val, best_state, wait = -1.0, None, 0\n",
    "\n",
    "def eval_loader(loader):\n",
    "    model.eval(); yT=[]; yP=[]; L=0.0; N=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logit = model(x); loss = crit(logit,y)\n",
    "            L += float(loss.item())*y.numel(); N += int(y.numel())\n",
    "            yT.append(y.cpu().numpy()); yP.append(logit.argmax(1).cpu().numpy())\n",
    "    yT = np.concatenate(yT) if yT else np.array([],dtype=np.int64)\n",
    "    yP = np.concatenate(yP) if yP else np.array([],dtype=np.int64)\n",
    "    f1 = f1_score(yT, yP, average=\"macro\") if len(yT)>0 else 0.0\n",
    "    return (L/max(1,N)), f1, yT, yP\n",
    "\n",
    "for ep in range(1, 41):\n",
    "    model.train(); runL=0.0; N=0; ytr=[]; ypr=[]\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        logit = model(x); loss = crit(logit,y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        runL += float(loss.item())*y.numel(); N += int(y.numel())\n",
    "        ytr.append(y.cpu().numpy()); ypr.append(logit.argmax(1).detach().cpu().numpy())\n",
    "    trF = f1_score(np.concatenate(ytr), np.concatenate(ypr), average=\"macro\") if N>0 else 0.0\n",
    "    _, vaF, yv, pv = eval_loader(val_loader)\n",
    "    _, teF, yt, pt = eval_loader(test_loader)\n",
    "    print(f\"Epoch {ep:02d}/40 | Train F1: {trF:.4f} | Val F1: {vaF:.4f} | Test F1: {teF:.4f} | L: {runL/max(1,N):.4f}\")\n",
    "    if vaF > best_val + 1e-5:\n",
    "        best_val, best_state, wait = vaF, {k:v.cpu() for k,v in model.state_dict().items()}, 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"âš ï¸ Early stop\"); break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) æœ€ç»ˆæµ‹è¯•æŠ¥å‘Šï¼ˆç¨³å®šç‰ˆï¼šæ˜¾å¼æŒ‡å®š labels=range(5)ï¼‰\n",
    "# ----------------------------\n",
    "_, _, ytrue, ypred = eval_loader(test_loader)  # é‡æ–°è¯„ä¼°è·å¾—æœ€ç»ˆé¢„æµ‹\n",
    "names = [f\"a_{n}\" for n in FIVE_LABELS]\n",
    "all_labels = list(range(len(FIVE_LABELS)))\n",
    "print(\"\\nğŸ¯ æœ€ç»ˆæµ‹è¯•é›†æ€§èƒ½ (Test Set):\\n\")\n",
    "print(classification_report(\n",
    "    ytrue, ypred,\n",
    "    labels=all_labels,\n",
    "    target_names=names,\n",
    "    digits=2,\n",
    "    zero_division=0\n",
    "))\n",
    "print(\"æ··æ·†çŸ©é˜µ:\")\n",
    "print(confusion_matrix(ytrue, ypred, labels=all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74032d7c-8449-445d-a535-83006a899ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pack] train: (2729, 3, 15, 32, 1) (2729,)\n",
      "[pack] val  : (1874, 3, 15, 32, 1) (1874,)\n",
      "[pack] test : (2448, 3, 15, 32, 1) (2448,)\n",
      "âœ… Repacked with win=15, stride=5, strict=False, mode='center'.\n"
     ]
    }
   ],
   "source": [
    "# === Fix window_label å®‰å…¨å¤„ç†ç©ºçª—å£ + é‡æ–°æ‰“åŒ…ï¼ˆwin=15, stride=5, strict=False, centerï¼‰ ===\n",
    "import stgcn_fiveclass_pipeline as p\n",
    "from collections import Counter\n",
    "\n",
    "# 1) çŒ´å­è¡¥ä¸ï¼šæ›¿æ¢åŸ window_labelï¼ˆé¿å…ä¸­å¿ƒ/å¤šæ•°æŠ•ç¥¨åœ¨ç©ºåˆ—è¡¨æ—¶å´©æºƒï¼‰\n",
    "def window_label_fix(window_labels, mode: str = \"center\"):\n",
    "    # window_labels: é•¿åº¦=win çš„å­—ç¬¦ä¸²/None åˆ—è¡¨\n",
    "    if mode == \"center\":\n",
    "        # å…è®¸ç©ºæˆ–ä¸­å¿ƒä¸º None æ—¶è¿”å› None\n",
    "        if not window_labels:\n",
    "            return None\n",
    "        mid = len(window_labels) // 2\n",
    "        v = window_labels[mid]\n",
    "        return v if (v in p.FIVE_SET) else None\n",
    "    else:  # \"majority\"\n",
    "        valid = [v for v in window_labels if v in p.FIVE_SET]\n",
    "        if not valid:\n",
    "            return None\n",
    "        return Counter(valid).most_common(1)[0][0]\n",
    "\n",
    "# åº”ç”¨è¡¥ä¸\n",
    "p.window_label = window_label_fix\n",
    "\n",
    "# 2) é‡æ–°æ‰“åŒ…ï¼ˆçŸ­çª—å£ï¼‰\n",
    "paths = p.DefaultPaths(\n",
    "    lab_16gz=\"data/labels_16GZ.npy\",\n",
    "    lab_17jp=\"data/labels_17JP.npy\",\n",
    "    lab_19mm=\"data/labels_19MM.npy\",\n",
    ")\n",
    "p.pack_train_val_test(\n",
    "    win=15,\n",
    "    stride=5,\n",
    "    strict=False,     # åªè¦æ±‚ä¸­å¿ƒå¸§ä¸ºäº”ç±»\n",
    "    mode=\"center\",    # ä½¿ç”¨ä¸­å¿ƒå¸§ä½œä¸ºçª—å£æ ‡ç­¾ï¼ˆå·²å®‰å…¨å¤„ç†ï¼‰\n",
    "    paths=paths\n",
    ")\n",
    "\n",
    "print(\"âœ… Repacked with win=15, stride=5, strict=False, mode='center'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1230be0-d796-43f0-bfd8-d70578abf089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 09SY windows: (1916, 3, 15, 32, 1) (1916,)\n"
     ]
    }
   ],
   "source": [
    "from stgcn_fiveclass_pipeline import make_windows_stgcn_from_paths, FIVE_LABELS\n",
    "import numpy as np\n",
    "\n",
    "x_path = \"data/poses_09SY_cs_nz.npy\"\n",
    "lab_out = \"data/labels_09SY.npy\"          # â† ç”¨åŸå§‹çš„ï¼Œä¸è¦ *_kept.npy\n",
    "k_idx  = \"data/poses_09SY_kept_idx.npy\"\n",
    "win, stride, strict, mode = 15, 5, False, \"center\"\n",
    "\n",
    "Xseq, Yseq = make_windows_stgcn_from_paths(\n",
    "    x_path, lab_out, k_idx, win=win, stride=stride, strict=strict, mode=mode\n",
    ")\n",
    "np.savez_compressed(\"data/test_09sy_stgcn.npz\", X=Xseq, Y=Yseq, meta=dict(labels=FIVE_LABELS))\n",
    "print(\"[OK] 09SY windows:\", Xseq.shape, Yseq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe85a05-4449-494b-b8fe-60c2fd3a8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16GZ] X=(2729, 3, 15, 32, 1), Y=(2729,), class_cnt=Counter({np.int64(2): 1585, np.int64(3): 591, np.int64(0): 420, np.int64(4): 96, np.int64(1): 37})\n",
      "[17JP] X=(1874, 3, 15, 32, 1), Y=(1874,), class_cnt=Counter({np.int64(3): 625, np.int64(2): 619, np.int64(0): 530, np.int64(4): 77, np.int64(1): 23})\n",
      "[19MM] X=(2448, 3, 15, 32, 1), Y=(2448,), class_cnt=Counter({np.int64(2): 1037, np.int64(3): 540, np.int64(0): 530, np.int64(4): 188, np.int64(1): 153})\n",
      "[09SY] X=(1916, 3, 15, 32, 1), Y=(1916,), class_cnt=Counter({np.int64(2): 894, np.int64(3): 840, np.int64(0): 117, np.int64(4): 65})\n",
      "\n",
      "[ALL] X=(8967, 3, 15, 32, 1), Y=(8967,), class_cnt=Counter({np.int64(2): 4135, np.int64(3): 2596, np.int64(0): 1597, np.int64(4): 426, np.int64(1): 213})\n",
      "\n",
      "[SPLIT]\n",
      " Train: (6276, 3, 15, 32, 1) {np.int64(0): 1118, np.int64(1): 149, np.int64(2): 2894, np.int64(3): 1817, np.int64(4): 298}\n",
      " Val  : (1345, 3, 15, 32, 1) {np.int64(0): 239, np.int64(1): 32, np.int64(2): 620, np.int64(3): 390, np.int64(4): 64}\n",
      " Test : (1346, 3, 15, 32, 1) {np.int64(0): 240, np.int64(1): 32, np.int64(2): 621, np.int64(3): 389, np.int64(4): 64}\n",
      "\n",
      "[OK] Saved to data/train_stgcn.npz, data/val_stgcn.npz, data/test_stgcn.npz\n"
     ]
    }
   ],
   "source": [
    "# === åˆå¹¶ 16GZ/17JP/19MM/09SY â†’ ç»Ÿä¸€çª—å£åŒ– â†’ åˆ†å±‚éšæœºåˆ’åˆ† Train/Val/Test (70/15/15) ===\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from stgcn_fiveclass_pipeline import make_windows_stgcn_from_paths, FIVE_LABELS\n",
    "\n",
    "# ç»Ÿä¸€çª—å£å‚æ•°ï¼ˆä¸ä½ å½“å‰æµç¨‹ä¸€è‡´ï¼‰\n",
    "WIN, STRIDE, STRICT, MODE = 15, 5, False, \"center\"\n",
    "\n",
    "# å››ä¸ªæ•°æ®æºçš„è·¯å¾„ï¼ˆå·²å®Œæˆï¼šä¸­å¿ƒåŒ–/å°ºåº¦å½’ä¸€/å»é›¶å¸§ + åŸå§‹é€å¸§æ ‡ç­¾ + kept_idxï¼‰\n",
    "SOURCES = [\n",
    "    dict(name=\"16GZ\",\n",
    "         x=\"data/poses_16GZ_cs_nz.npy\",\n",
    "         y=\"data/labels_16GZ.npy\",\n",
    "         k=\"data/poses_16GZ_kept_idx.npy\"),\n",
    "    dict(name=\"17JP\",\n",
    "         x=\"data/poses_17JP_cs_nz.npy\",\n",
    "         y=\"data/labels_17JP.npy\",\n",
    "         k=\"data/poses_17JP_kept_idx.npy\"),\n",
    "    dict(name=\"19MM\",\n",
    "         x=\"data/poses_19MM_cs_nz.npy\",\n",
    "         y=\"data/labels_19MM.npy\",\n",
    "         k=\"data/poses_19MM_kept_idx.npy\"),\n",
    "    dict(name=\"09SY\",\n",
    "         x=\"data/poses_09SY_cs_nz.npy\",\n",
    "         y=\"data/labels_09SY.npy\",\n",
    "         k=\"data/poses_09SY_kept_idx.npy\"),\n",
    "]\n",
    "\n",
    "def pack_one(src):\n",
    "    X, Y = make_windows_stgcn_from_paths(\n",
    "        src[\"x\"], src[\"y\"], src[\"k\"],\n",
    "        win=WIN, stride=STRIDE, strict=STRICT, mode=MODE\n",
    "    )\n",
    "    # Y æ˜¯( N, ) çš„å¯¹è±¡æ•°ç»„ï¼ˆäº”ç±»å­—ç¬¦ä¸²åæˆ–å·²æ˜ å°„ä¸ºidï¼Œå–å†³äºä½ çš„å®ç°ï¼‰\n",
    "    # ç»Ÿä¸€è½¬æˆç±»åˆ« idï¼ˆ0..4ï¼‰\n",
    "    name2id = {n:i for i,n in enumerate(FIVE_LABELS)}\n",
    "    if Y.dtype.kind in (\"U\",\"O\",\"S\"):  # å­—ç¬¦ä¸²\n",
    "        Yid = np.array([name2id[y] for y in Y], dtype=np.int64)\n",
    "    else:\n",
    "        Yid = Y.astype(np.int64)\n",
    "    print(f\"[{src['name']}] X={X.shape}, Y={Yid.shape}, class_cnt={Counter(Yid)}\")\n",
    "    return X, Yid\n",
    "\n",
    "# 1) åˆ†åˆ«çª—å£åŒ–å¹¶æ±‡æ€»\n",
    "Xs, Ys = [], []\n",
    "for s in SOURCES:\n",
    "    Xi, Yi = pack_one(s)\n",
    "    Xs.append(Xi); Ys.append(Yi)\n",
    "\n",
    "X_all = np.concatenate(Xs, axis=0)       # (N, 3, T, 32, 1)\n",
    "Y_all = np.concatenate(Ys, axis=0)       # (N,)\n",
    "print(f\"\\n[ALL] X={X_all.shape}, Y={Y_all.shape}, class_cnt={Counter(Y_all)}\")\n",
    "\n",
    "# 2) åˆ†å±‚åˆ’åˆ† Train/Val/Test = 70/15/15\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X_all, Y_all, test_size=0.15, random_state=42, stratify=Y_all\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.1764706, random_state=42, stratify=y_tmp\n",
    ")\n",
    "# å¤‡æ³¨ï¼š0.1764706 â‰ˆ 0.15 / 0.85ï¼Œä½¿å¾—æœ€ç»ˆ 70/15/15\n",
    "\n",
    "def cnt(y): return dict(sorted(Counter(y).items()))\n",
    "print(\"\\n[SPLIT]\")\n",
    "print(\" Train:\", X_train.shape, cnt(y_train))\n",
    "print(\" Val  :\", X_val.shape,   cnt(y_val))\n",
    "print(\" Test :\", X_test.shape,  cnt(y_test))\n",
    "\n",
    "# 3) ä¿å­˜åˆ°æ ‡å‡†æ–‡ä»¶åï¼Œä¾›è®­ç»ƒä»£ç ç›´æ¥ä½¿ç”¨\n",
    "np.savez_compressed(\"data/train_stgcn.npz\", X=X_train, Y=y_train, meta=dict(labels=FIVE_LABELS))\n",
    "np.savez_compressed(\"data/val_stgcn.npz\",   X=X_val,   Y=y_val,   meta=dict(labels=FIVE_LABELS))\n",
    "np.savez_compressed(\"data/test_stgcn.npz\",  X=X_test,  Y=y_test,  meta=dict(labels=FIVE_LABELS))\n",
    "print(\"\\n[OK] Saved to data/train_stgcn.npz, data/val_stgcn.npz, data/test_stgcn.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480f5602-b669-4a33-8921-3b3c882306e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Before ==\n",
      "train: {0: 1118, 1: 149, 2: 2894, 3: 1817, 4: 298}\n",
      "\n",
      "== After  (oversampled) ==\n",
      "train_over: {0: 1118, 1: 1490, 2: 2894, 3: 1817, 4: 2604}\n",
      "\n",
      "[OK] Saved oversampled train -> data/train_stgcn_over.npz\n"
     ]
    }
   ],
   "source": [
    "# === Oversample lie(1) & bend(4) in TRAIN set, save to train_stgcn_over.npz ===\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "npz_in  = \"data/train_stgcn.npz\"\n",
    "npz_out = \"data/train_stgcn_over.npz\"\n",
    "\n",
    "# æ ‡ç­¾ç¼–å·ï¼ˆå¦‚ä¸ä½ ä¸ä¸€è‡´è¯·æ”¹è¿™é‡Œï¼‰\n",
    "SIT, LIE, STAND, WALK, BEND = 0, 1, 2, 3, 4\n",
    "\n",
    "dat = np.load(npz_in, allow_pickle=True)\n",
    "X, Y = dat[\"X\"], dat[\"Y\"]\n",
    "labels = dat[\"meta\"].item().get(\"labels\", [\"sit\",\"lie\",\"stand\",\"walk\",\"bend\"])\n",
    "\n",
    "def show_cnt(tag, y):\n",
    "    c = Counter(y.tolist())\n",
    "    ordered = {k:c.get(k,0) for k in range(5)}\n",
    "    print(f\"{tag}: {ordered}\")\n",
    "    return ordered\n",
    "\n",
    "print(\"== Before ==\")\n",
    "cnt_before = show_cnt(\"train\", Y)\n",
    "\n",
    "# ç›®æ ‡è§„æ¨¡ï¼šæŠŠå°‘æ•°ç±»æå‡åˆ°å¤šæ•°ç±»çš„ ~80%-90%\n",
    "max_c = max(cnt_before.values()) if cnt_before else 0\n",
    "target = cnt_before.copy()\n",
    "target[LIE]  = min(int(max_c * 0.85), max_c)   # lie ç›®æ ‡â‰ˆå¤šæ•°ç±»çš„85%\n",
    "target[BEND] = min(int(max_c * 0.90), max_c)   # bend ç›®æ ‡â‰ˆå¤šæ•°ç±»çš„90%\n",
    "\n",
    "# è®¡ç®—æ¯ç±»éœ€è¦çš„é‡å¤å€æ•°ï¼ˆä¸Šé™é¿å…è¿‡åº¦å¤åˆ¶ï¼‰\n",
    "R_MAX = 10\n",
    "repeats = {k:1 for k in range(5)}\n",
    "for k in [LIE, BEND]:\n",
    "    n = cnt_before.get(k,0)\n",
    "    if n > 0:\n",
    "        repeats[k] = min(R_MAX, int(np.ceil(target[k] / n)))\n",
    "    else:\n",
    "        repeats[k] = 1  # æ²¡æœ‰è¯¥ç±»å°±ä¸é‡å¤ï¼ˆå¯è€ƒè™‘æ•°æ®å¢å¼ºè¡¥é½ï¼‰\n",
    "\n",
    "# æ„é€ è¿‡é‡‡æ ·åçš„ç´¢å¼•\n",
    "idx_all = np.arange(len(Y))\n",
    "idx_per_class = {k: idx_all[Y == k] for k in range(5)}\n",
    "\n",
    "new_idx = []\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for k in range(5):\n",
    "    idx_k = idx_per_class[k]\n",
    "    if len(idx_k) == 0:\n",
    "        continue\n",
    "    rep = repeats[k]\n",
    "    if rep <= 1:\n",
    "        new_idx.append(idx_k)\n",
    "    else:\n",
    "        # é‡å¤ rep æ¬¡åï¼Œè‹¥è¶…å‡ºç›®æ ‡æ•°é‡åˆ™éšæœºæˆªæ–­åˆ° target[k]\n",
    "        tiled = np.tile(idx_k, rep)\n",
    "        if k in (LIE, BEND):\n",
    "            need = target[k]\n",
    "            if len(tiled) > need:\n",
    "                tiled = rng.choice(tiled, size=need, replace=False)\n",
    "        new_idx.append(tiled)\n",
    "\n",
    "# å…¶ä»–ç±»åˆ«ï¼ˆæœªæŒ‡å®šç›®æ ‡ï¼‰çš„æ ·æœ¬ç›´æ¥åŠ å…¥\n",
    "#ï¼ˆä¸Šé¢å·²åŠ å…¥ï¼›è‹¥æƒ³ä¸¥æ ¼å¯¹é½åˆ°åŒä¸€è§„æ¨¡ï¼Œå¯åŒæ ·è®¾ç½® target å¹¶æˆªæ–­ï¼‰\n",
    "\n",
    "new_idx = np.concatenate(new_idx)\n",
    "rng.shuffle(new_idx)\n",
    "\n",
    "X_over = X[new_idx]\n",
    "Y_over = Y[new_idx]\n",
    "\n",
    "print(\"\\n== After  (oversampled) ==\")\n",
    "cnt_after = show_cnt(\"train_over\", Y_over)\n",
    "\n",
    "# ä¿å­˜\n",
    "np.savez_compressed(npz_out, X=X_over, Y=Y_over, meta=dict(labels=labels))\n",
    "print(f\"\\n[OK] Saved oversampled train -> {npz_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d7988c-27ed-4a53-84be-14a9bc4349d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Adjacency (merged): (1, 32, 32)\n",
      "Class weights: [1.5700000524520874, 1.1799999475479126, 0.6100000143051147, 0.9700000286102295, 0.6700000166893005]\n",
      "Epoch 01/80 | Train F1: 0.4151 | Val F1: 0.3006 | Test F1: 0.3054\n",
      "Epoch 02/80 | Train F1: 0.4913 | Val F1: 0.4090 | Test F1: 0.4122\n",
      "Epoch 03/80 | Train F1: 0.5276 | Val F1: 0.3849 | Test F1: 0.3914\n",
      "Epoch 04/80 | Train F1: 0.5410 | Val F1: 0.4695 | Test F1: 0.4446\n",
      "Epoch 05/80 | Train F1: 0.5672 | Val F1: 0.4815 | Test F1: 0.4622\n",
      "Epoch 06/80 | Train F1: 0.5865 | Val F1: 0.4561 | Test F1: 0.4384\n",
      "Epoch 07/80 | Train F1: 0.6123 | Val F1: 0.4737 | Test F1: 0.4881\n",
      "Epoch 08/80 | Train F1: 0.6286 | Val F1: 0.5040 | Test F1: 0.4822\n",
      "Epoch 09/80 | Train F1: 0.6379 | Val F1: 0.5331 | Test F1: 0.5253\n",
      "Epoch 10/80 | Train F1: 0.6571 | Val F1: 0.4112 | Test F1: 0.4011\n",
      "Epoch 11/80 | Train F1: 0.6673 | Val F1: 0.5029 | Test F1: 0.5151\n",
      "Epoch 12/80 | Train F1: 0.6737 | Val F1: 0.5528 | Test F1: 0.5660\n",
      "Epoch 13/80 | Train F1: 0.6869 | Val F1: 0.5677 | Test F1: 0.5353\n",
      "Epoch 14/80 | Train F1: 0.6985 | Val F1: 0.5092 | Test F1: 0.4878\n",
      "Epoch 15/80 | Train F1: 0.7072 | Val F1: 0.4793 | Test F1: 0.4735\n",
      "Epoch 16/80 | Train F1: 0.7207 | Val F1: 0.5542 | Test F1: 0.5497\n",
      "Epoch 17/80 | Train F1: 0.7237 | Val F1: 0.4351 | Test F1: 0.4124\n",
      "Epoch 18/80 | Train F1: 0.7376 | Val F1: 0.5890 | Test F1: 0.5657\n",
      "Epoch 19/80 | Train F1: 0.7434 | Val F1: 0.5780 | Test F1: 0.5680\n",
      "Epoch 20/80 | Train F1: 0.7482 | Val F1: 0.6130 | Test F1: 0.5932\n",
      "Epoch 21/80 | Train F1: 0.7582 | Val F1: 0.6210 | Test F1: 0.5995\n",
      "Epoch 22/80 | Train F1: 0.7570 | Val F1: 0.5801 | Test F1: 0.5449\n",
      "Epoch 23/80 | Train F1: 0.7681 | Val F1: 0.5672 | Test F1: 0.5818\n",
      "Epoch 24/80 | Train F1: 0.7682 | Val F1: 0.6523 | Test F1: 0.6378\n",
      "Epoch 25/80 | Train F1: 0.7699 | Val F1: 0.6221 | Test F1: 0.5947\n",
      "Epoch 26/80 | Train F1: 0.7875 | Val F1: 0.6065 | Test F1: 0.6075\n",
      "Epoch 27/80 | Train F1: 0.7903 | Val F1: 0.6123 | Test F1: 0.6139\n",
      "Epoch 28/80 | Train F1: 0.7948 | Val F1: 0.5915 | Test F1: 0.5856\n",
      "Epoch 29/80 | Train F1: 0.8006 | Val F1: 0.6042 | Test F1: 0.6010\n",
      "Epoch 30/80 | Train F1: 0.7934 | Val F1: 0.6669 | Test F1: 0.6703\n",
      "Epoch 31/80 | Train F1: 0.8134 | Val F1: 0.5551 | Test F1: 0.6055\n",
      "Epoch 32/80 | Train F1: 0.8054 | Val F1: 0.6405 | Test F1: 0.6254\n",
      "Epoch 33/80 | Train F1: 0.8147 | Val F1: 0.6187 | Test F1: 0.6333\n",
      "Epoch 34/80 | Train F1: 0.8288 | Val F1: 0.6197 | Test F1: 0.6239\n",
      "Epoch 35/80 | Train F1: 0.8274 | Val F1: 0.6639 | Test F1: 0.6556\n",
      "Epoch 36/80 | Train F1: 0.8405 | Val F1: 0.6595 | Test F1: 0.6497\n",
      "Epoch 37/80 | Train F1: 0.8394 | Val F1: 0.6256 | Test F1: 0.6259\n",
      "Epoch 38/80 | Train F1: 0.8337 | Val F1: 0.6784 | Test F1: 0.6576\n",
      "Epoch 39/80 | Train F1: 0.8519 | Val F1: 0.6640 | Test F1: 0.6549\n",
      "Epoch 40/80 | Train F1: 0.8549 | Val F1: 0.6552 | Test F1: 0.6586\n",
      "Epoch 41/80 | Train F1: 0.8454 | Val F1: 0.5536 | Test F1: 0.5625\n",
      "Epoch 42/80 | Train F1: 0.8418 | Val F1: 0.6920 | Test F1: 0.6808\n",
      "Epoch 43/80 | Train F1: 0.8581 | Val F1: 0.6599 | Test F1: 0.6598\n",
      "Epoch 44/80 | Train F1: 0.8609 | Val F1: 0.6400 | Test F1: 0.6486\n",
      "Epoch 45/80 | Train F1: 0.8619 | Val F1: 0.6723 | Test F1: 0.6781\n",
      "Epoch 46/80 | Train F1: 0.8628 | Val F1: 0.6934 | Test F1: 0.6814\n",
      "Epoch 47/80 | Train F1: 0.8701 | Val F1: 0.6576 | Test F1: 0.6622\n",
      "Epoch 48/80 | Train F1: 0.8843 | Val F1: 0.6780 | Test F1: 0.6875\n",
      "Epoch 49/80 | Train F1: 0.8736 | Val F1: 0.7091 | Test F1: 0.7062\n",
      "Epoch 50/80 | Train F1: 0.8702 | Val F1: 0.6793 | Test F1: 0.6717\n",
      "Epoch 51/80 | Train F1: 0.8807 | Val F1: 0.6849 | Test F1: 0.6772\n",
      "Epoch 52/80 | Train F1: 0.8832 | Val F1: 0.6502 | Test F1: 0.6721\n",
      "Epoch 53/80 | Train F1: 0.8860 | Val F1: 0.6717 | Test F1: 0.6886\n",
      "Epoch 54/80 | Train F1: 0.8752 | Val F1: 0.6894 | Test F1: 0.6993\n",
      "Epoch 55/80 | Train F1: 0.8995 | Val F1: 0.6273 | Test F1: 0.6229\n",
      "Epoch 56/80 | Train F1: 0.8880 | Val F1: 0.6501 | Test F1: 0.6539\n",
      "Epoch 57/80 | Train F1: 0.8959 | Val F1: 0.6999 | Test F1: 0.7086\n",
      "Epoch 58/80 | Train F1: 0.8958 | Val F1: 0.6141 | Test F1: 0.6164\n",
      "Epoch 59/80 | Train F1: 0.9047 | Val F1: 0.7034 | Test F1: 0.7116\n",
      "Epoch 60/80 | Train F1: 0.8893 | Val F1: 0.6255 | Test F1: 0.5804\n",
      "Epoch 61/80 | Train F1: 0.9005 | Val F1: 0.7233 | Test F1: 0.7065\n",
      "Epoch 62/80 | Train F1: 0.8999 | Val F1: 0.6952 | Test F1: 0.6840\n",
      "Epoch 63/80 | Train F1: 0.8885 | Val F1: 0.5772 | Test F1: 0.5456\n",
      "Epoch 64/80 | Train F1: 0.9098 | Val F1: 0.7273 | Test F1: 0.7086\n",
      "Epoch 65/80 | Train F1: 0.9107 | Val F1: 0.6915 | Test F1: 0.6930\n",
      "Epoch 66/80 | Train F1: 0.9129 | Val F1: 0.6893 | Test F1: 0.6931\n",
      "Epoch 67/80 | Train F1: 0.9113 | Val F1: 0.7283 | Test F1: 0.7183\n",
      "Epoch 68/80 | Train F1: 0.9224 | Val F1: 0.7014 | Test F1: 0.7190\n",
      "Epoch 69/80 | Train F1: 0.9201 | Val F1: 0.6933 | Test F1: 0.6783\n",
      "Epoch 70/80 | Train F1: 0.9067 | Val F1: 0.6955 | Test F1: 0.6934\n",
      "Epoch 71/80 | Train F1: 0.9132 | Val F1: 0.5938 | Test F1: 0.6123\n",
      "Epoch 72/80 | Train F1: 0.9236 | Val F1: 0.7013 | Test F1: 0.6514\n",
      "Epoch 73/80 | Train F1: 0.9186 | Val F1: 0.7082 | Test F1: 0.6761\n",
      "Epoch 74/80 | Train F1: 0.9276 | Val F1: 0.7336 | Test F1: 0.7211\n",
      "Epoch 75/80 | Train F1: 0.9140 | Val F1: 0.6863 | Test F1: 0.6966\n",
      "Epoch 76/80 | Train F1: 0.9246 | Val F1: 0.7122 | Test F1: 0.7012\n",
      "Epoch 77/80 | Train F1: 0.9265 | Val F1: 0.6910 | Test F1: 0.6937\n",
      "Epoch 78/80 | Train F1: 0.9261 | Val F1: 0.7293 | Test F1: 0.6921\n",
      "Epoch 79/80 | Train F1: 0.9235 | Val F1: 0.6922 | Test F1: 0.6994\n",
      "Epoch 80/80 | Train F1: 0.9271 | Val F1: 0.6649 | Test F1: 0.6842\n",
      "âœ… Best Val F1: 0.7336 | Weights saved to data/best_stgcn.pth\n",
      "\n",
      "ğŸ¯ Test macro-F1: 0.6842\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      a_walk       0.54      0.71      0.62       240\n",
      "       a_lie       0.74      0.88      0.80        32\n",
      "     a_stand       0.82      0.67      0.74       621\n",
      "       a_sit       0.77      0.85      0.81       389\n",
      "      a_bend       0.48      0.44      0.46        64\n",
      "\n",
      "    accuracy                           0.72      1346\n",
      "   macro avg       0.67      0.71      0.68      1346\n",
      "weighted avg       0.74      0.72      0.72      1346\n",
      "\n",
      "Confusion matrix:\n",
      "[[170   1  39  23   7]\n",
      " [  0  28   1   3   0]\n",
      " [117   5 416  63  20]\n",
      " [ 17   3  35 331   3]\n",
      " [  8   1  19   8  28]]\n"
     ]
    }
   ],
   "source": [
    "# ==== ST-GCNï¼šè‡ªåŠ¨å¯¹é½æ¯å—è¾“å…¥é€šé“ï¼ˆæŒ‰ä¸Šä¸€å—è¾“å‡ºï¼‰+ K=1 å›¾ + 3â†’16 é€‚é… + è®­ç»ƒ/è¯„ä¼° ====\n",
    "import os, numpy as np, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# ä½ çš„ pipeline\n",
    "import stgcn_fiveclass_pipeline as p\n",
    "STGCN              = p.STGCN\n",
    "STGCNWindowDataset = p.STGCNWindowDataset\n",
    "Graph              = p.Graph\n",
    "FIVE_LABELS        = p.FIVE_LABELS\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------- æ•°æ® ----------\n",
    "train_path = \"data/train_stgcn_over.npz\" if os.path.exists(\"data/train_stgcn_over.npz\") else \"data/train_stgcn.npz\"\n",
    "val_path   = \"data/val_stgcn.npz\"\n",
    "test_path  = \"data/test_stgcn.npz\"\n",
    "\n",
    "train_ds = STGCNWindowDataset(train_path)\n",
    "val_ds   = STGCNWindowDataset(val_path)\n",
    "test_ds  = STGCNWindowDataset(test_path)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# ---------- å›¾ï¼šåˆå¹¶å¤šå­å›¾ä¸ºå•å›¾(K=1) ----------\n",
    "A = np.asarray(Graph().A, dtype=np.float32)\n",
    "if A.ndim == 2:\n",
    "    A = A[None, ...]\n",
    "elif A.ndim == 3 and A.shape[0] != 1:\n",
    "    A = A.sum(axis=0, keepdims=True)\n",
    "print(\"Adjacency (merged):\", A.shape)\n",
    "\n",
    "# ---------- è¾“å…¥é€‚é…ï¼š3 â†’ 16 ----------\n",
    "class InputAdapter(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=16):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "    def forward(self, x):  # (N,3,T,V)\n",
    "        return self.proj(x)\n",
    "\n",
    "adapter = InputAdapter(3, 16).to(device)\n",
    "\n",
    "# ---------- æ¨¡å‹æœ¬ä½“ ----------\n",
    "model_core = STGCN(in_channels=16, num_class=len(FIVE_LABELS), A=A).to(device)\n",
    "\n",
    "# ---------- è¡¥ä¸â‘ ï¼šA å¤åˆ¶åˆ°æ¯ä¸ª GCN çš„ num_subset ----------\n",
    "def _replicate_A_for_module_A(A_np, num_subset):\n",
    "    if A_np.ndim == 2:\n",
    "        A_np = A_np[None, ...]\n",
    "    if A_np.shape[0] != num_subset:\n",
    "        A_np = np.repeat(A_np, num_subset, axis=0)\n",
    "    return torch.tensor(A_np, dtype=torch.float32)\n",
    "\n",
    "for m in model_core.modules():\n",
    "    if m.__class__.__name__ == \"GCN\" and hasattr(m, \"A\") and hasattr(m, \"num_subset\"):\n",
    "        m.A = _replicate_A_for_module_A(A, m.num_subset).to(device)\n",
    "\n",
    "# ---------- è¡¥ä¸â‘¡ï¼šè‡ªåŠ¨æŠŠ g2/g3/g4 çš„ conv_d è¾“å…¥é€šé“ï¼Œæ”¹æˆâ€œä¸Šä¸€å—è¾“å‡ºé€šé“â€ ----------\n",
    "def _set_conv_in_channels(conv2d: nn.Conv2d, in_ch: int) -> nn.Conv2d:\n",
    "    # ä¿ç•™ kernel/stride/padding/dilation/out_channels ç­‰ï¼Œæ›¿æ¢ in_channels\n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=in_ch,\n",
    "        out_channels=conv2d.out_channels,\n",
    "        kernel_size=conv2d.kernel_size,\n",
    "        stride=conv2d.stride,\n",
    "        padding=conv2d.padding,\n",
    "        dilation=conv2d.dilation,\n",
    "        groups=conv2d.groups,\n",
    "        bias=(conv2d.bias is not None),\n",
    "    )\n",
    "    return new_conv\n",
    "\n",
    "def _block_out_channels(gcn_module) -> int:\n",
    "    # ä»¥ç¬¬ä¸€æ”¯ conv_d çš„ out_channels ä½œä¸ºè¯¥å—è¾“å‡ºé€šé“ï¼ˆä½ çš„å®ç°é‡Œå„æ”¯ä¸€è‡´ï¼‰\n",
    "    return int(gcn_module.conv_d[0].out_channels)\n",
    "\n",
    "# ä¾æ¬¡åˆ—å‡ºå—ï¼ˆå¦‚æœ‰å°±å–ï¼‰\n",
    "blocks = [getattr(model_core, n) for n in (\"g1\",\"g2\",\"g3\",\"g4\") if hasattr(model_core, n)]\n",
    "# ç¬¬ä¸€å—çš„è¾“å…¥é€šé“ç­‰äºé€‚é…å™¨è¾“å‡º 16ï¼Œä¸æ”¹ï¼›ä»ç¬¬äºŒå—å¼€å§‹å¯¹é½è¾“å…¥é€šé“ = ä¸Šä¸€å—è¾“å‡ºé€šé“\n",
    "prev_out = _block_out_channels(blocks[0])  # g1 çš„ out_channelsï¼Œé€šå¸¸ 64\n",
    "for blk in blocks[1:]:\n",
    "    # æŠŠæœ¬å—çš„æ¯ä¸ª conv_d çš„ in_channels æ”¹æˆ prev_out\n",
    "    new_list = []\n",
    "    for conv in blk.conv_d:\n",
    "        new_list.append(_set_conv_in_channels(conv, prev_out).to(device))\n",
    "    # æ›¿æ¢ ModuleList\n",
    "    blk.conv_d = nn.ModuleList(new_list)\n",
    "    # æ›´æ–° prev_out = å½“å‰å—çš„è¾“å‡ºé€šé“\n",
    "    prev_out = _block_out_channels(blk)\n",
    "\n",
    "# ---------- åŒ…è£…æœ€ç»ˆæ¨¡å‹ï¼šå…ˆé€‚é…é€šé“å†è¿‡æ ¸å¿ƒ ----------\n",
    "class WrappedSTGCN(nn.Module):\n",
    "    def __init__(self, adapter, core):\n",
    "        super().__init__()\n",
    "        self.adapter = adapter\n",
    "        self.core = core\n",
    "    def forward(self, x):\n",
    "        x = self.adapter(x)\n",
    "        return self.core(x)\n",
    "\n",
    "model = WrappedSTGCN(adapter, model_core).to(device)\n",
    "\n",
    "# ---------- ç±»åˆ«æƒé‡ ----------\n",
    "y_train = np.load(train_path)[\"Y\"]\n",
    "from collections import Counter\n",
    "cnt = Counter(y_train.tolist()); tot = sum(cnt.values())\n",
    "weights = np.array([tot / max(cnt.get(i,1),1) for i in range(len(FIVE_LABELS))], dtype=np.float32)\n",
    "weights = weights / weights.mean()\n",
    "print(\"Class weights:\", weights.round(2).tolist())\n",
    "crit = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n",
    "opt  = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "EPOCHS, PATIENCE = 80, 12\n",
    "\n",
    "# ---------- è¯„ä¼° ----------\n",
    "@torch.no_grad()\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    yT, yP = [], []\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        yP.append(out.argmax(1).cpu().numpy())\n",
    "        yT.append(y.cpu().numpy())\n",
    "    yT = np.concatenate(yT); yP = np.concatenate(yP)\n",
    "    return f1_score(yT, yP, average=\"macro\", zero_division=0), yT, yP\n",
    "\n",
    "# ---------- è®­ç»ƒï¼ˆæ—©åœ+ä¿å­˜æœ€ä¼˜ï¼‰ ----------\n",
    "best_val, best_state, wait = -1.0, None, 0\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    yT, yP = [], []\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = crit(out, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        yT.append(y.detach().cpu().numpy())\n",
    "        yP.append(out.argmax(1).detach().cpu().numpy())\n",
    "    yT = np.concatenate(yT); yP = np.concatenate(yP)\n",
    "    tr_f1 = f1_score(yT, yP, average=\"macro\", zero_division=0)\n",
    "\n",
    "    va_f1,_,_ = eval_loader(val_loader)\n",
    "    te_f1,_,_ = eval_loader(test_loader)\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS} | Train F1: {tr_f1:.4f} | Val F1: {va_f1:.4f} | Test F1: {te_f1:.4f}\")\n",
    "\n",
    "    if va_f1 > best_val:\n",
    "        best_val = va_f1\n",
    "        best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(\"âš ï¸ Early stop\"); break\n",
    "\n",
    "# ---------- ä¿å­˜/æµ‹è¯• ----------\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"data/best_stgcn.pth\")\n",
    "print(f\"âœ… Best Val F1: {best_val:.4f} | Weights saved to data/best_stgcn.pth\")\n",
    "\n",
    "te_f1, ytrue, ypred = eval_loader(test_loader)\n",
    "print(\"\\nğŸ¯ Test macro-F1:\", round(te_f1,4))\n",
    "names = [f\"a_{n}\" for n in FIVE_LABELS]\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(ytrue, ypred, labels=list(range(len(FIVE_LABELS))), target_names=names, digits=2, zero_division=0))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytrue, ypred, labels=list(range(len(FIVE_LABELS)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62ec5d-0605-4b7e-ac8e-82356b711dbd",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1fe41-4649-4d90-a169-6e04abd9d11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
